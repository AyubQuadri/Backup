vec = c(1,2,3,4,5,6,7,8,9,10,1,2,3,4,2,3,4,3,4,4)
length(vec)
mean(vec)
median(vec)
quantile(vec)
sd(vec)
var(vec)
rm(ls())
ls()
rm(list = ls())
M=matrix(c(1,2,3,4),nrow=2,ncol=2,byrow=TRUE) # to create a matrix
ls()
rm(M)
data = data.frame(v1,v2,v3) # to create a data frame
names(data)
colnames(data)
names(data) = c("ID","Name","Selected") # to assign variable names
data1 = data[,c(2:3)]
#Handling missing values in the data
rm(list=c("m","x","y"))
rm(list = ls())
install.packages("car")
library(car)
scatterplotMatrix(~mpg+disp+drat+wt, data=mtcars, main="Scatter Plot Matrix")
scatterplotMatrix(~mpg+disp+drat+wt|cyl, data=mtcars, main="Three Cylinder Options")
#connect points with line, #add regression line
p1 <- ggplot(mtcars, aes(x = hp, y = mpg))
x <- 1:3
names(x)
names(x) <- c("foo", "bar", "norf")
x
names(x)
x <- c(2,4,6,6,8,2)
x[1]
x[2]
x[1:4]
x[x > 2]
u <- x  >2
u
x[u]
ls()
M=matrix(c(1,2,3,4),nrow=2,ncol=2,byrow=TRUE) # to create a matrix
ls()
rm(M)
data = data.frame(v1,v2,v3) # to create a data frame
v1=c(1,2,3,4,5) #numeric vector
v2=c("a","b","c","d","e") #character vector
v3=c(TRUE,FALSE,TRUE,FALSE,TRUE) #logical vector
v4 = c(10,9,8,7,6,5)
data = data.frame(v1,v2,v3) # to create a data frame
names(data)
colnames(data)
names(data) = c("ID","Name","Selected") # to assign variable names
rm(list = ls())
attach(mtcars)
data<-mtcars
apply(data,2,min) #This generates the min values for each numeric attribute
apply(data,1,max)
A<-apply(data[,2:11],2,min)
A<-data.frame(min=apply(data[,2:11],2,min))
B<-apply(data[,2:11],2,max)
B
stat<-function(x){
"Mean"=mean(x)
"Min"=min(x)
"Max"=max(x)
A<-data.frame(Min,Mean,Max)
return(A)
}
stats<-apply(data[,2:11],2,FUN=stat) ##Observe the ouptput of apply.. it is a list
stats
result<-do.call(rbind,stats)
View(result)
data1<-data[,c("mpg","cyl")]
View(data1)
name<-c("mpg","cyl","disp","hp")
data1<-data[names(data)%in% name] ## %in% comes in handy for subsetting
View(data1)
select(data,mpg,cyl,disp,hp)
library(dplyr)
select(data,mpg,cyl,disp,hp)
filter(data,mpg>25 | gear==5)
library(DMwR)
data(algae)
x<-data(algae)
cleanAlgae <- knnImputation(algae)
x<-data(algae)
x
cleanAlgae <- knnImputation(algae)
summary(cleanAlgae)
algae
sum(is.na(algae))
sum(is.na(cleanAlgae))
tapply(data$rbi,data$team,FUN= sum,na.rm=T)
baseball
library(vegan)
library(infotheo)
rm(list=ls())
setwd("C:/Users/quadris/Desktop/My Learning/INSOFE CPEE/Day 7/20170114_Batch24_CSE7202c_LinearRegression_Lab01/20170114_Batch24_CSE7202c_Simpl_Lin_Reg_Lab01")
auto=read.csv("auto.csv")
auto
View(auto)
str(auto)
summary(auto)
attach(auto)
plot(weight1, mpg)
cor(weight1,mpg)
lr_auto=lm(mpg~weight1,data=auto)
class(lr_auto)
abline(lr_auto,col="red", lwd=2)
summary(lr_auto)
plot(lr_auto)
OV = auto$mpg
OV-FV
FV = lr_auto$fitted.values
RE = residuals(lr_auto)
OV = auto$mpg
OV-FV
library(DMwR)
regr.eval(auto$mpg,lr_auto$fitted.values)
plot(lr_auto,which = 4)
anova(lr_auto)
1-((196.28/24)/((369.57+196.28)/25)
1-((196.28/24)/((369.57+196.28)/25))
1-((196.28/24)/((369.57+196.28)/25))
View(auto)
require(caTools)
set.seed(123)
setwd("C:/Users/quadris/Desktop/My Learning/INSOFE CPEE/Day 7/20170114_Batch24_CSE7202c_LinearRegression_Lab01/20170114_Batch24_CSE7202c_Simpl_Lin_Reg_Lab01")
auto1 <-read.csv("auto.csv")
require(caTools)
set.seed(123)
sample = sample.split(auto1, SplitRatio = .70)
train = subset(auto1, sample == TRUE)
test = subset(auto1, sample == FALSE)
26*0.7
26*0.3
attach(auto1)
plot(weight1, mpg)
cor(weight1,mpg)
lr_auto=lm(mpg~weight1,data=auto)
abline(lr_auto,col="red", lwd=2)
summary(lr_auto)
attach(auto1)
plot(weight1, mpg)
cor(weight1,mpg)
lr_auto=lm(mpg~weight1,data=auto1)
abline(lr_auto1,col="red", lwd=2)
lr_auto1=lm(mpg~weight1,data=auto1)
abline(lr_auto1,col="red", lwd=2)
summary(lr_auto1)
attach(train)
plot(weight1, mpg)
cor(weight1,mpg)
lr_train=lm(mpg~weight1,data=train)
abline(lr_train,col="red", lwd=2)
summary(lr_train)
plot(lr_train)
test
test$weight1
for(i in test$weight1)
{
y[]=39.2365-6.0534*(i)
}
for(i in test$weight1)
{
y=39.2365-6.0534*(i)
}
y
for(i in test$weight1)
{
y$temp=39.2365-6.0534*(i)
}
rm(list=ls())
setwd("C:/Users/quadris/Desktop/My Learning/INSOFE CPEE/Day 7/20170114_Batch24_CSE7202c_LinearRegression_Lab01/20170114_Batch24_CSE7202c_Simpl_Lin_Reg_Lab01")
auto1 <-read.csv("auto.csv")
require(caTools)
set.seed(123)
sample = sample.split(auto1, SplitRatio = .70)
train = subset(auto1, sample == TRUE)
test = subset(auto1, sample == FALSE)
attach(train)
plot(weight1, mpg)
cor(weight1,mpg)
lr_train=lm(mpg~weight1,data=train)
abline(lr_train,col="red", lwd=2)
summary(lr_train)
View(train)
View(test)
y =39.2365-6.0534*(2.83)
y
y = 39.2365 - (6.0534*(4.08))
y
39.2365 - (6.0534*(2.83))
y = 39.2365 - (6.0534*(3.22))
y
rm(list= ls())
setwd("C:/Users/quadris/Desktop/My Learning/INSOFE CPEE/Day 7/20170114_Batch24_CSE7202c_LinearRegression_Lab01/20170114_Batch24_CSE7202c_Simpl_Lin_Reg_Lab01")
read.csv("Toyota_SimpleReg.csv")
data <- read.csv("Toyota_SimpleReg.csv")
str(data)
View(data)
is.na(data)
sum(is.na(data))
data$id = NULL
data
data <subset(data, select= c(2:))
data <- subset(data, select= c(2:))
data <- subset(data, select= c(2:4))
View(data)
sum(is.na(data))
data <- read.csv("Toyota_SimpleReg.csv")
data$id <- NULL
View(data)
data <- subset(data, select= c(2:4))
sum(is.na(data))
View(data)
str(data)
require(caTools)
sample = sample.split(data, SplitRatio = .70)
train = subset(data, sample == TRUE)
test = subset(data, sample == FALSE)
attach(data)
lm_Out <- lm(price~Age_12_16, data = data)
lm_Out = lm(price~Age_12_16, data = train)
attach(train)
View(train)
attach(train)
lm_Out = lm(Price~Age_12_16, data = train)
abline(lm_Out,col="red", lwd=2)
summary(lm_Out)
View(test)
26226.458 -172.052*13500
plot(Age_12_16, Price)
cor(Age_12_16,Price)
lm_Out = lm(Price~Age_12_16, data = train)
abline(lm_Out,col="red", lwd=2)
summary(lm_Out)
26226.458 -172.052*57
View(test)
26226.458 -172.052*53
17107.7-16500
predict(lm_Out, test)
coefficients(lm_Out[1]+coefficients(lm_Out)[2]*53)
as.numeric( coefficients(lm_Out[1]+coefficients(lm_Out)[2]*53))
as.numeric( coefficients(lm_Out)[1]+coefficients(lm_Out)[2]*53))
as.numeric( coefficients(lm_Out)[1]+coefficients(lm_Out)[2]*53)
library(DMwR)
regr.eval(train$Age_12_16,lm_Out$fitted.values)
regr.eval(train$Age_12_16, predict(lm_Out,test))
regr.eval(test$Age_12_16, predict(lm_Out,test))
regr.eval(train$Age_12_16,lm_Out$fitted.values)
regr.eval(test$Age_12_16, predict(lm_Out,test))
regr.eval(train$Age_12_16,lm_Out$fitted.values)
#test data
regr.eval(test$Age_12_16, predict(lm_Out,test))
anova(lm_Out)
FV = lm_Out$fitted.values
RE = residuals(lm_Out)
OV = test$Age_12_16
OV-FV
lm_Out = lm(Price~Age_12_16, data = train)
abline(lm_Out,col="red", lwd=2)
summary(lm_Out)
as.numeric( coefficients(lm_Out)[1]+coefficients(lm_Out)[2]*53)
as.numeric( coefficients(lm_Out)[1]+coefficients(lm_Out)[2]*57)
View(test)
rm(list= ls())
setwd("C:/Users/quadris/Desktop/My Learning/INSOFE CPEE/Day 7/20170114_Batch24_CSE7202c_LinearRegression_Lab01/20170114_Batch24_CSE7202c_Simpl_Lin_Reg_Lab01")
data <- read.csv("Toyota_SimpleReg.csv")
str(data)
class(data)
#drop ID column and check na values
data <- subset(data, select= c(2:4))
sum(is.na(data))
# split the data into train and test
require(caTools)
sample = sample.split(data, SplitRatio = .70)
train = subset(data, sample == TRUE)
test = subset(data, sample == FALSE)
attach(train)
plot(Age_12_16, Price)
cor(Age_12_16,Price)
lm_Out = lm(Price~Age_12_16, data = train)
abline(lm_Out,col="red", lwd=2)
summary(lm_Out)
lm_out[4]
lm_out
lm_Out
View(test)
as.numeric( coefficients(lm_Out)[1]+coefficients(lm_Out)[2]*58)
predict(lm_Out, test)
library(DMwR)
regr.eval(train$Age_12_16,lm_Out$fitted.values)
#test data
regr.eval(test$Age_12_16, predict(lm_Out,test))
anova(lm_Out)
FV = lm_Out$fitted.values
RE = residuals(lm_Out)
OV = test$Price
OV = train$Price
FV-OV
R<- FV-OV
if(R = RE){print(TRUE)}
R = RE
R == RE
library(DMwR)
regr.eval(train$Age_12_16,lm_Out$fitted.values)
#test data
regr.eval(test$Age_12_16, predict(lm_Out,test))
summary(lm_Out)
plot(lm_Out)
regr.eval(train$Age_12_16,lm_Out$fitted.values)
#test data
regr.eval(test$Age_12_16, predict(lm_Out,test))
plot(lm_Out,which = 4)
which(rownames(train)%in%c(110,112,116))
lr_auto_Noinfl<- lm(Price~., data=train[-c(110,112,116),])
summary(lr_auto_Noinfl)
lm_Out = lm(Price~Age_12_16, data = data)
plot(lm_Out,which = 4)
lm_Out = lm(Price~Age_12_16, data = test)
plot(lm_Out,which = 4)
regr.eval(train$Age_12_16,lm_Out$fitted.values)
library(DMwR)
regr.eval(train$Age_12_16,lm_Out$fitted.values)
data <- read.csv("Toyota_SimpleReg.csv")
str(data)
rm(list= ls())
setwd()
getwd()
data <- read.csv("Toyota_SimpleReg.csv")
str(data)
data <- subset(data, select= c(2:4))
sum(is.na(data))
require(caTools)
sample = sample.split(data, SplitRatio = .70)
train = subset(data, sample == TRUE)
test = subset(data, sample == FALSE)
attach(train)
plot(Age_12_16, Price)
cor(Age_12_16,Price)
lm_Out = lm(Price~Age_12_16, data = test)
abline(lm_Out,col="red", lwd=2)
summary(lm_Out)
plot(lm_Out)
library(DMwR)
regr.eval(train$Age_12_16,lm_Out$fitted.values)
lm_Out = lm(Price~Age_12_16, data = test)
abline(lm_Out,col="red", lwd=2)
summary(lm_Out)
library(DMwR)
regr.eval(train$Age_12_16,lm_Out$fitted.values)
#test data
regr.eval(test$Age_12_16, predict(lm_Out,test))
x<-c(68,42,51,57,56,80,45,39,36,79)
summary(x)
mean(x)
sd(x)
count(x)
x <-(91,150,109,90,200,198,51,155,172)
m <-matrix(x,nrow = 3,ncol = 3,byrow = FALSE)
m
x <-c(91,150,109,90,200,198,51,155,172)
m <-matrix(x,nrow = 3,ncol = 3,byrow = FALSE)
m
colnames(m) <-c("Monthly Check","Occasional Check","Never")
m
rownames(m) <-c("Under 45","45-59","60 and Over")
m
sum(m[1,])
sum(m[1:3,])
sum(m[1,])
sum(m[2,])
sum(m[3,])
sum(m[,1])
sum(m[,2])
sum(m[,3])
sum(sum(m[1,]),sum(m[2,]),sum(m[3,]))
sum(sum(m[,1]),
sum(m[,2]),
sum(m[,3]))
232*350/1216
505*350/1216
479*350/1216
232*488/1216
505*488/1216
479*488/1216
232*378/1216
505*378/1216
479*378/1216
m
chisq.test(m)
pnorm(3)
qf(0.05,2,6,lower.tail = FALSE)
setwd("C:/Users/quadris/Desktop/My Learning/INSOFE CPEE/GNQ/20170115_Bacth24_CSE7315c_GNQ_DataSets/20170115_Bacth24_CSE7315c_GNQ_DataSets")
data <- read.csv("housing.csv",header = T,sep = ",")
sum(is.na(data))
View(data)
library(DMwR)
data2<-centralImputation(data) #Cenral Imputation
sum(is.na(data2))
View(data2)
library(infotheo)
IncomeBin <- discretize(data2$Distance, disc="equalfreq",nbins=5)
IncomeBin
table(IncomeBin)
IncomeBin <- discretize(data2$Distance, disc="equalwidth",nbins=5)
table(IncomeBin)
library(infotheo)
IncomeBin <- discretize(data2$Distance, disc="equalfreq",nbins=5)
table(IncomeBin)
tapply(data2$Distance,IncomeBin,min)
View(data2)
View(data2)
tapply(data2$Distance,IncomeBin,max)
IncomeBin <- discretize(data2$Distance, disc="equalfreq",nbins=5)
IncomeBin
library(caTools)
require(caTools)
set.seed(123)
sample = sample.split(data, SplitRatio = .70)
train = subset(data, sample == TRUE)
test = subset(data, sample == FALSE)
506*0.7
set.seed(123)
sample = sample.split(data, SplitRatio = .75)
train = subset(data, sample == TRUE)
test = subset(data, sample == FALSE)
506*.75
506*0.25
library(caTools)
require(caTools)
set.seed(123)
sample = sample.split(data, SplitRatio = .75)
train = subset(data, sample == TRUE)
test = subset(data, sample == FALSE) # test 144
Data_NumAtr<-subset(data2,select=c(Age))
Data_NumAtr<-subset(data2,select=c(AGE))
Data_NumAtr
library(vegan)
dataStd <- decostand(Data_NumAtr,"standardize")
summary(dataStd)
library(dummies)
RADDummyVars<-dummy(data2$RAD)
head(RADDummyVars)
class(RADDummyVars)
str(RADDummyVars)
as.factor(RADDummyVars)
str(RADDummyVars)
class(RADDummyVars)
as.factor(RADDummyVars)
hist(data2$TAX, col="green", xlab="TAX",main="Histogram of TAX")
boxplot(data2$OwnOcc, main="Variation of income as a function of education",
xlab="Education", ylab="Income")
hist(data2$TAX, main ="distribution of TAX")
m <- ggplot(data2, aes(x=TAX))
library(ggplot2)
m <- ggplot(data2, aes(x=TAX))
m + geom_histogram(bins=10)
m + geom_histogram(bins=10,aes(fill=..count..))
hist(data2$TAX, col="green", xlab="TAX",main="Histogram of TAX")
m <- ggplot(data2, aes(x=TAX))
m + geom_histogram(bins=10)
m + geom_histogram(bins=10,aes(fill=..count..))
library(ggplot2)
p <- ggplot(data2, aes(factor(Ownocc), RAD))
p + geom_boxplot()
p <- ggplot(data2, aes(factor(data2$Ownocc), RAD))
p <- ggplot(data2, aes(factor(data2$Ownocc), data2$RAD))
p + geom_boxplot()
p <- ggplot(data2, aes(factor(data2$Ownocc), data2$RAD))
p + geom_boxplot())
attach(data2)
p <- ggplot(data2, aes(factor(Ownocc),RAD))
p + geom_boxplot()
p <- ggplot(data2, aes(factor(data2$Ownocc),RAD))
p + geom_boxplot()
All_Numeric = subset(data, select=-c(CHAS,RAD,TAX))
boxplot(All_Numeric)
summary(All_Numeric)
quantile(All_Numeric)
All_Numeric = subset(data2, select=-c(CHAS,RAD,TAX)) #created sub set with all numeric values
summary(All_Numeric)
quantile(All_Numeric)
vec = c(1,2,3,4,5,6,7,8,9,10,1,2,3,4,2,3,4,3,4,4)
quantile(vec)
quantile(All_Numeric$Crimerate)
quantile(All_Numeric$ResiLandZone)
quantile(All_Numeric$INDUS)
quantile(All_Numeric$NOX)
quantile(All_Numeric$Rooms)
quantile(All_Numeric$AGE)
quantile(All_Numeric$Distance)
quantile(All_Numeric$PTRATIO)
quantile(All_Numeric$Blacks)
quantile(All_Numeric$LSTAT)
quantile(All_Numeric$OwnOcc)
p <- ggplot(data2, aes(factor(data2$Ownocc),RAD))
p + geom_boxplot()
p <- ggplot(data2, aes(factor(data2$Ownocc), data2$RAD))
p + geom_boxplot()
p <- ggplot(data2, aes(factor(data2$RAD), data2$OwnOcc))
p + geom_boxplot()
p + geom_boxplot() + geom_jitter()
p + geom_boxplot(outlier.colour = "green", outlier.size = 3) + geom_jitter()
p + geom_boxplot(aes(fill=RAD))
p + geom_boxplot(aes(fill=factor(RAD)))
IQR(All_Numeric)
IQR(All_Numeric$Crimerate)
IQR(All_Numeric$Crimerate)
IQR(All_Numeric$ResiLandZone)
