x <-"Hello World"
print(x)
y<- 1:5
y<- 1:5
z <- matrix(
data = 1:6,
nrow= 2,
ncol=3
)
z
a
a <- array (
data = 1:8,
dim = c(2,2,2)
)
a
l <- list(True,123L,1.34,"abc")
l <- list(TRUE,123L,1.34,"abc")
categories <- c("Male","Female","Male","Female","Male","Male")
factor<- factor(categories)
factor
levels(factor)
unclass(factor)
df <- data.frame(
Name = c("Cat","Dog","Cow","Pig"),
HowMany = c(5,10,12,32),
IsPet = c(TRUE,TRUE,FALSE,FALSE)
)
df
c(1,2,4)+ c(1,2,4,5)
c(1,2,4)+ c(4,5,6)
m <-matrix(data =1:6, nrow = 2,ncol = 3)
n <-matrix(1:6,2,3)
identical(m,n)
m=n
m==n
?data.frame
install.packages("dplyr")
library("dplyr")
?data.frame
mean(abs(rnom(100)))
mean(abs(rnorm(100)))
mean(abs(rnorm(100)))
mean(abs(rnorm(100)))
dev.off()
dev.off()
pdf("xh.pdf")
hist(rnorm(100))
dev.off()
x <- c(1,2,3)
print(x)
x <- c(4,5,6)
print(x)
mean(Nile)
Nile
hist(Nile)
q()
hist(Nile)
source('~/.active-rstudio-document')
oddCount <- function(x){
k <-0
for(n in x){
if(n %% 2 == 1)
K <- K+1
}
return (k)
}
oddCount(c(1,2,3,4,5,6,7))
oddCount(c(1,2,3,4,5,6,7))
oddCount(c(1,2,3,4,5,6,7))
oddCount <- function(x){
k <-0
for(n in x){
if(n %% 2 == 1)
k <- k+1
}
return (k)
}
oddCount(c(1,2,3,4,5,6,7))
oddCount(c(2,4,5,6,7,8,9,10))
oddCount <- function(x){
Odd <-0
Even <- 0
for(n in x){
if(n %% 2 == 1)
Odd <- Odd+1
else
Even <- Even+1
}
return (Odd, Even)
}
oddCount(c(1,2,3,4,5,6,7))
oddCount(c(1,2,3,4,5,6,7))
oddCount <- function(x){
k <-0
for(n in x){
if(n %% 2 == 1)
k <- k+1
}
return (k)
}
oddCount(c(1,2,3,4,5,6,7))
oddCount(c(2,4,5,6,7,8,9,10))
x <- c(4,"abc",9)
x
mode(x)
y <-c(1,2,3)
mode(y)
z <- c(TRUE,FALSE)
mode(z)
m <- rbind(c(1,3),c(5,7))
m
hn <- hist(Nile)
print(hn)
str(hn)
x_train <- input_variables_values_training_datasets
install.packages("rJava")
install.packages("rJava")
install.packages(rJava)
install.packages(rjava)
install.packages(rjava)
install.packages(rJava)
install.packages("rJava")
install.packages("rJava")
install.packages(rJava)
install.packages("rJava")
input <- mtcars[,c('mpg','cyl')]
print(head(input))
pritn(head(mtcars))
pritn(mtcars)
print(head(mtcars))
png(file = "boxplot.png")
boxplot(mpg ~ cyl, data= mtcars, xlab = "Number of Cylinders", ylab= "Miles Per Gallon", main="Milage Data")
dev.off()
png(file = "boxplot.png")
boxplot(mpg ~ cyl, data= mtcars, xlab = "Number of Cylinders", ylab= "Miles Per Gallon", main="Milage Data")
boxplot(mpg ~ cyl, data = mtcars, xlab = "Number of Cylinders",
png(file = "boxplot.png")
# Plot the chart.
boxplot(mpg ~ cyl, data = mtcars, xlab = "Number of Cylinders",
library('ggplot2') # visualization
library('ggthemes') # visualization
library('scales')
import.packages('ggplot2')
install.packages('ggplot2')
boxplot(mpg ~ cyl, data = mtcars, xlab = "Number of Cylinders",
ylab = "Miles Per Gallon", main = "Mileage Data")
# Save the file.
dev.off()
input <- mtcars[,c('mpg','cyl')]
print(head(input))
print(input)
??bind_rows
str
getwd()
dir
dir()
read.csv(file="*C:\Users\quadris\Desktop\simple.csv" , header=TRUE,sep=",")
read.csv(file="*C:\\Users\\quadris\\Desktop\\simple.csv" , header=TRUE,sep=",")
getwd()
read.csv(file="simple.csv" , header=TRUE,sep=",")
heisenberg <-read.csv(file="simple.csv" , header=TRUE,sep=",")
summary()
summary(heisenberg)
heisenberg
x <- c(11, 7.5, 8.5, 10, 10, 10.5, 5.5, 10, 9, 9.5, 5.25, 8, 6.5, 10.5, 8.75, 0, 6, 6, 6.75,
x
heisenberg
x <- c(11, 7.5, 8.5, 10, 10, 10.5, 5.5, 10, 9, 9.5, 5.25, 8, 6.5, 10.5, 8.75, 0, 6, 6, 6.75, 8.75, 0, 9.5, 7.5, 8.5, 7 );
x
summary(x)
boxplot(x)
var(x)
sd(x)
z = read.csv(file="sample.csv",header = TRUE,sep=",")
z = read.csv(file="sample.csv",header = TRUE,sep=",")
z = read.csv(file="simple1",header = TRUE,sep=",")
getwd()
heisenberg <-read.csv(file="simple.csv" , header=TRUE,sep=",")
heisenberg
summary(heisenberg)
boxplot(heisenberg)
x
summary(x)
var(x)
sd(x)
boxplot(heisenberg$Philips)
boxplot(heisenberg$Philips, heisenberg$Mathew)
boxplot(heisenberg$Philips as Philips, heisenberg$Mathew as Mathew)
boxplot(heisenberg$Philips, heisenberg$Mathew)
PrA <- c(.75,.25)
PrB <- c(6/9,5/7)
BayesTheorem(PrA, PrB)
BayesTheorem(PrA, PrBA)
install.packages('LaplacesDemon')
BayesTheorem(PrA, PrBA)
PrA <- c(.75,.25)
PrB <- c(6/9,5/7)
BayesTheorem(PrA, PrBA)
heisenberg <-read.csv(file="simple.csv" , header=TRUE,sep=",")
install.packages('LaplacesDemon')
PrA <- c(0.75,0.25)
PrBA <- c(6/9, 5/7)
BayesTheorem(PrA, PrBA)
libarary(LaplacesDemon)
library(LaplacesDemon)
PrA <- c(0.75,0.25)
PrBA <- c(6/9, 5/7)
BayesTheorem(PrA, PrBA)
BayesTheorem(PrA, PrBA)
slices <- c(10, 12, 4, 16, 8)
lbls <- c("US", "UK", "Australia", "Germany", "France")
pct <- round(slices/sum(slices)*100)
lbls <- paste(lbls, pct) # add percents to labels
lbls <- paste(lbls,"%",sep="") # ad % to labels
pie(slices,labels = lbls, col=rainbow(length(lbls)),
main="Pie Chart of Countries")
x <- c(4,2,4,3,11,6,4,4,1,4,2,3,3,1,2,2,6,0,2,1,3,2)
summary(x)
boxplot(x)
var(x)
sd(x)
hist(x)
duration = faithful$eruptions
breaks = seq(1.5,5.5, by=0.5)
duration.cut = cut(duration, breaks,right = FALSE)
duration.freq = table(duration.freq)
duration.cumrelfreq = duration.cumrelfreq/nrow(faithful)
cumrelfreq0 = c(0, duration.cumrelfreq)
plot(breaks, cumrelfreq0,main="Old Faithful Eruptions", xlab="Duration",
ylab="Cumulative frequency")
lines(breaks, cumrelfreq0)
cumrelfreq0 = c(0, duration.cumrelfreq)
duration.cumrelfreq = duration.cumfreq / nrow(faithful)
duration = faithful$eruptions
stem(duration)
eruptions
duration
library(googleVis)
Geo=gvisGeoChart(Exports, locationvar="Country",
colorvar="Profit",
options=list(projection="kavrayskiy-vii"))
plot(Geo)
require(datasets)
options=list(region="US",
states <- data.frame(state.name, state.x77)
GeoStates <- gvisGeoChart(states, "state.name", "Illiteracy",
x<- c(4,7,11,16,20,22,25,26,33)
summary(x)
mode(x)
getmode(x)
getmode <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
x<- c(4,7,11,16,20,22,25,26,33)
summary(x)
getmode(x)
x<- c(4,7,11,16,20,22,22,25,26,33)
getmode(x)
plot(cars)
df
rm(list=ls())
source('~/.active-rstudio-document', echo=TRUE)
install.packages("drat", repos="https://cran.rstudio.com")
drat:::addRepo("dmlc")
install.packages("mxnet")
(39-30)/16
(39-30)/4
(40-30)/4
(21-30)/4
pnorm(40,mean = 30,sd=4)
pnorm(21,mean = 30,sd=4)
1- pnorm(21,mean = 30,sd=4)
pnorm(40,mean = 30,sd=4,1e-3)
pnorm(40,mean = 30,sd=4)
sprintf("%.3f",0.9937903)
foreach(STDIN)
sapply(STDIN,FUN = pnorm(STDIN,mean=30,sd=4))
STDIN <- c(40,21,30,35)
sapply(STDIN,FUN = pnorm(STDIN,mean=30,sd=4))
sapply(STDIN,FUN (pnorm(STDIN,mean=30,sd=4)))
sapply(STDIN,function(x) pnorm(STDIN,mean=30,sd=4))
pnorm(40,mean = 30,sd=4)
abc <-sapply(STDIN,function(x) pnorm(STDIN,mean=30,sd=4))
abc<-abc[,1]
abc
sprintf(%.3f,abc)
sapply(abc, function(x) sprintf(%.3f,abc))
sapply(abc, function(x) sprintf(%.3f,x))
sprintf(%.3f,x)
sprintf(%.3f,x[1,])
sprintf(%.3f,abc[1,])
abc[1,]
abc[1,]
abc
abc(1)
abc[1]
for(i<=length(abc))
length(abc)
Result[i]
result <- NULL
for(i<length(abc))
i=0
for(i<length(abc))
result <- sprintf("%.3f",abc[])
result
result <- sprintf("%.3f",abc)
result
abc[2] <- 1-abc[2]
abc[3] <- abc[3]-abc[4]
abc
abc[4]<- Null
abc[4]<- NA
abc
abc <- abc(1:3)
abc <- abc[1:3]
abc
result <- sprintf("%.3f",abc)
result
rm(list = ls())
setwd("C:\Users\quadris\Desktop\data science\data set\MLWare-2")
data <- read.csv("train.csv", header = TRUE,sep=",")
rm(list = ls())
setwd("C:\Users\quadris\Desktop\data science\data set\MLWare-2")
data <- read.csv("train", header = TRUE,sep=",")
data <- read.csv("train", header = TRUE,sep=",")
data <- read.csv("train.csv", header = TRUE,sep=",")
View(data)
rm(list = ls())
source('~/.active-rstudio-document', echo=TRUE)
setwd("C:/Users/quadris/Desktop/data science/data set/MLWare-2")
data <- read.csv("train.csv", header = TRUE,sep=",")
data= data[-1]
unique(data$userId)
length(unique(data$userId))
length(unique(data$itemId))
sapply(function(x) sum(is.na(data)))
sapply(function(x), sum(is.na(data)))
sapply(data, function(x) sum(is.na(data)))
data$userId<- as.factor(as.character(data$userId))
data$itemId<- as.factor(as.character(data$itemId))
unique(data$rating)
data$rating<- as.factor(as.character(data$rating))
unique(data$rating)
glmOut <- glm(rating ~., data = data,family = "binomial")
write.csv(file = data, header=T,sep=",")
write.csv(file = data, header=T)
write.csv(file = 'data.csv', header=T)
write.csv(data, file = "data.csv",row.names = TRUE)
test <- read.csv("test.csv",header = TRUE,sep=",")
test =test[-1]
length(unique(test$userId))
length(unique(test$itemId))
sapply(test, function(x) sum(is.na(x)))
test$userId<- as.factor(as.character(test$userId))
test$itemId<- as.factor(as.character(test$itemId))
test$rating<- as.factor(as.character(testta$rating))
write.csv(test, file = "test1.csv",row.names = TRUE)
rm(list = ls())
setwd("C:/Users/quadris/Desktop/My Learning/INSOFE CPEE/Day 20 SVM/lab activity")
getwd()
Housing <- read.csv("UniversalBank.csv",header = T,sep = ",")
Housing <- Housing[-c=('ID','ZIP.Code')]
Housing <- Housing[-(c=('ID','ZIP.Code'))]
Housing <- Housing[-('ID','ZIP.Code')]
Housing <- Housing[-'ID''ZIP.Code']
Housing <- Housing[-1]
Housing <- Housing[-4]
dummies <- as.numeric(Housing$Education >=2)
Housing$Education <- as.numeric(Housing$Education >=2)
library(vegan)
Housing <- decostand(Housing[,-1],"range")
set.seed(100) # for reproducing results
set.seed(100) # for reproducing results
rowIndices <- 1 : nrow(Housing) # prepare row indices
sampleSize <- 0.8 * length(rowIndices) # training sample size
trainingRows <- sample (rowIndices, sampleSize) # random sampling
trainingData <- Housing[trainingRows, ] # training data
testData <- Housing[-trainingRows, ] # test data
library(e1071)
x = subset (trainingRows, select = -Personal.Loan)
x = subset(trainingRows, select = -Personal.Loan)
x = trainingData[-Personal.Loan]
y= trainingData$Personal.Loan
x = subset(trainingData, select = c(-Personal.Loan))
model  =  svm(x,y, method = "C-classification", kernel = "linear", cost = 10, gamma = 0.1)
summary(model)
source('~/.active-rstudio-document', echo=TRUE)
dummy(Housing$Education)
rm(list = ls())
setwd("C:/Users/quadris/Desktop/My Learning/INSOFE CPEE/Day 20 SVM/lab activity")
Bank <- read.csv("UniversalBank.csv",header = T,sep = ",")
Bank <- Bank[-1]
Bank <- Bank[-4]
library(dummies)
EduDummyVars<-dummy(Bank$edu)
EduDummyVars<-dummy(Bank$Education)
EduDummyVars
head(EduDummyVars)
EduDummyVars
Bank<-data.frame(Bank,EduDummyVars)
head(Bank)
Bank <- Bank[-'Education']
Bank <- Bank[-Bank$Education]
Bank <- read.csv("UniversalBank.csv",header = T,sep = ",")
Bank <- Bank[-Bank$ID]
Bank <- read.csv("UniversalBank.csv",header = T,sep = ",")
Bank <- Bank[-Bank$ID]
Bank <- read.csv("UniversalBank.csv",header = T,sep = ",")
Bank <- Bank[-1]
Bank <- Bank[-4]
Bank <- Bank[-6]
library(dummies)
EduDummyVars<-dummy(Bank$Education)
Bank <- read.csv("UniversalBank.csv",header = T,sep = ",")
Bank <- Bank[-1]
Bank <- Bank[-4]
library(dummies)
EduDummyVars<-dummy(Bank$Education)
head(EduDummyVars)
Bank<-data.frame(Bank,EduDummyVars)
Bank <- Bank[-6]
head(Bank)
library(vegan)
Bank <- decostand(Bank[,-Bank$Personal.Loan],"range")
set.seed(100) # for reproducing results
rowIndices <- 1 : nrow(Bank) # prepare row indices
sampleSize <- 0.8 * length(rowIndices) # training sample size
trainingRows <- sample (rowIndices, sampleSize) # random sampling
trainingData <- Bank[trainingRows, ] # training data
testData <- Bank[-trainingRows, ] # test data
library(e1071)
y= trainingData$Personal.Loan
x = subset(trainingData, select = c(-Personal.Loan))
model  =  svm(x,y, method = "C-classification", kernel = "linear", cost = 10, gamma = 0.1)
summary(model)
compareTable <- table(predict(model),Bank$Personal.Loan);compareTable
head(Bank)
unique(y)
head(x)
model  =  svm(x,y, method = "C-classification", kernel = "linear", cost = 10, gamma = 0.1)
summary(model)
print(model)
compareTable <- table(predict(model),x);compareTable
compareTable <- table(predict(model),y);compareTable
tuned <- tune.svm(Sex ~., data = trainingData, gamma = 10^(-3:1), cost = 2^(0:9))
tuned <- tune.svm(Personal.Loan ~., data = trainingData, gamma = 10^(-3:1), cost = 2^(0:9))
