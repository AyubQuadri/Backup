x <-"Hello World"
print(x)
y<- 1:5
y<- 1:5
z <- matrix(
data = 1:6,
nrow= 2,
ncol=3
)
z
a
a <- array (
data = 1:8,
dim = c(2,2,2)
)
a
l <- list(True,123L,1.34,"abc")
l <- list(TRUE,123L,1.34,"abc")
categories <- c("Male","Female","Male","Female","Male","Male")
factor<- factor(categories)
factor
levels(factor)
unclass(factor)
df <- data.frame(
Name = c("Cat","Dog","Cow","Pig"),
HowMany = c(5,10,12,32),
IsPet = c(TRUE,TRUE,FALSE,FALSE)
)
df
c(1,2,4)+ c(1,2,4,5)
c(1,2,4)+ c(4,5,6)
m <-matrix(data =1:6, nrow = 2,ncol = 3)
n <-matrix(1:6,2,3)
identical(m,n)
m=n
m==n
?data.frame
install.packages("dplyr")
library("dplyr")
?data.frame
mean(abs(rnom(100)))
mean(abs(rnorm(100)))
mean(abs(rnorm(100)))
mean(abs(rnorm(100)))
dev.off()
dev.off()
pdf("xh.pdf")
hist(rnorm(100))
dev.off()
x <- c(1,2,3)
print(x)
x <- c(4,5,6)
print(x)
mean(Nile)
Nile
hist(Nile)
q()
hist(Nile)
source('~/.active-rstudio-document')
oddCount <- function(x){
k <-0
for(n in x){
if(n %% 2 == 1)
K <- K+1
}
return (k)
}
oddCount(c(1,2,3,4,5,6,7))
oddCount(c(1,2,3,4,5,6,7))
oddCount(c(1,2,3,4,5,6,7))
oddCount <- function(x){
k <-0
for(n in x){
if(n %% 2 == 1)
k <- k+1
}
return (k)
}
oddCount(c(1,2,3,4,5,6,7))
oddCount(c(2,4,5,6,7,8,9,10))
oddCount <- function(x){
Odd <-0
Even <- 0
for(n in x){
if(n %% 2 == 1)
Odd <- Odd+1
else
Even <- Even+1
}
return (Odd, Even)
}
oddCount(c(1,2,3,4,5,6,7))
oddCount(c(1,2,3,4,5,6,7))
oddCount <- function(x){
k <-0
for(n in x){
if(n %% 2 == 1)
k <- k+1
}
return (k)
}
oddCount(c(1,2,3,4,5,6,7))
oddCount(c(2,4,5,6,7,8,9,10))
x <- c(4,"abc",9)
x
mode(x)
y <-c(1,2,3)
mode(y)
z <- c(TRUE,FALSE)
mode(z)
m <- rbind(c(1,3),c(5,7))
m
hn <- hist(Nile)
print(hn)
str(hn)
x_train <- input_variables_values_training_datasets
install.packages("rJava")
install.packages("rJava")
install.packages(rJava)
install.packages(rjava)
install.packages(rjava)
install.packages(rJava)
install.packages("rJava")
install.packages("rJava")
install.packages(rJava)
install.packages("rJava")
input <- mtcars[,c('mpg','cyl')]
print(head(input))
pritn(head(mtcars))
pritn(mtcars)
print(head(mtcars))
png(file = "boxplot.png")
boxplot(mpg ~ cyl, data= mtcars, xlab = "Number of Cylinders", ylab= "Miles Per Gallon", main="Milage Data")
dev.off()
png(file = "boxplot.png")
boxplot(mpg ~ cyl, data= mtcars, xlab = "Number of Cylinders", ylab= "Miles Per Gallon", main="Milage Data")
boxplot(mpg ~ cyl, data = mtcars, xlab = "Number of Cylinders",
png(file = "boxplot.png")
# Plot the chart.
boxplot(mpg ~ cyl, data = mtcars, xlab = "Number of Cylinders",
library('ggplot2') # visualization
library('ggthemes') # visualization
library('scales')
import.packages('ggplot2')
install.packages('ggplot2')
boxplot(mpg ~ cyl, data = mtcars, xlab = "Number of Cylinders",
ylab = "Miles Per Gallon", main = "Mileage Data")
# Save the file.
dev.off()
input <- mtcars[,c('mpg','cyl')]
print(head(input))
print(input)
??bind_rows
str
getwd()
dir
dir()
read.csv(file="*C:\Users\quadris\Desktop\simple.csv" , header=TRUE,sep=",")
read.csv(file="*C:\\Users\\quadris\\Desktop\\simple.csv" , header=TRUE,sep=",")
getwd()
read.csv(file="simple.csv" , header=TRUE,sep=",")
heisenberg <-read.csv(file="simple.csv" , header=TRUE,sep=",")
summary()
summary(heisenberg)
heisenberg
x <- c(11, 7.5, 8.5, 10, 10, 10.5, 5.5, 10, 9, 9.5, 5.25, 8, 6.5, 10.5, 8.75, 0, 6, 6, 6.75,
x
heisenberg
x <- c(11, 7.5, 8.5, 10, 10, 10.5, 5.5, 10, 9, 9.5, 5.25, 8, 6.5, 10.5, 8.75, 0, 6, 6, 6.75, 8.75, 0, 9.5, 7.5, 8.5, 7 );
x
summary(x)
boxplot(x)
var(x)
sd(x)
z = read.csv(file="sample.csv",header = TRUE,sep=",")
z = read.csv(file="sample.csv",header = TRUE,sep=",")
z = read.csv(file="simple1",header = TRUE,sep=",")
getwd()
heisenberg <-read.csv(file="simple.csv" , header=TRUE,sep=",")
heisenberg
summary(heisenberg)
boxplot(heisenberg)
x
summary(x)
var(x)
sd(x)
boxplot(heisenberg$Philips)
boxplot(heisenberg$Philips, heisenberg$Mathew)
boxplot(heisenberg$Philips as Philips, heisenberg$Mathew as Mathew)
boxplot(heisenberg$Philips, heisenberg$Mathew)
PrA <- c(.75,.25)
PrB <- c(6/9,5/7)
BayesTheorem(PrA, PrB)
BayesTheorem(PrA, PrBA)
install.packages('LaplacesDemon')
BayesTheorem(PrA, PrBA)
PrA <- c(.75,.25)
PrB <- c(6/9,5/7)
BayesTheorem(PrA, PrBA)
heisenberg <-read.csv(file="simple.csv" , header=TRUE,sep=",")
install.packages('LaplacesDemon')
PrA <- c(0.75,0.25)
PrBA <- c(6/9, 5/7)
BayesTheorem(PrA, PrBA)
libarary(LaplacesDemon)
library(LaplacesDemon)
PrA <- c(0.75,0.25)
PrBA <- c(6/9, 5/7)
BayesTheorem(PrA, PrBA)
BayesTheorem(PrA, PrBA)
slices <- c(10, 12, 4, 16, 8)
lbls <- c("US", "UK", "Australia", "Germany", "France")
pct <- round(slices/sum(slices)*100)
lbls <- paste(lbls, pct) # add percents to labels
lbls <- paste(lbls,"%",sep="") # ad % to labels
pie(slices,labels = lbls, col=rainbow(length(lbls)),
main="Pie Chart of Countries")
x <- c(4,2,4,3,11,6,4,4,1,4,2,3,3,1,2,2,6,0,2,1,3,2)
summary(x)
boxplot(x)
var(x)
sd(x)
hist(x)
duration = faithful$eruptions
breaks = seq(1.5,5.5, by=0.5)
duration.cut = cut(duration, breaks,right = FALSE)
duration.freq = table(duration.freq)
duration.cumrelfreq = duration.cumrelfreq/nrow(faithful)
cumrelfreq0 = c(0, duration.cumrelfreq)
plot(breaks, cumrelfreq0,main="Old Faithful Eruptions", xlab="Duration",
ylab="Cumulative frequency")
lines(breaks, cumrelfreq0)
cumrelfreq0 = c(0, duration.cumrelfreq)
duration.cumrelfreq = duration.cumfreq / nrow(faithful)
duration = faithful$eruptions
stem(duration)
eruptions
duration
library(googleVis)
Geo=gvisGeoChart(Exports, locationvar="Country",
colorvar="Profit",
options=list(projection="kavrayskiy-vii"))
plot(Geo)
require(datasets)
options=list(region="US",
states <- data.frame(state.name, state.x77)
GeoStates <- gvisGeoChart(states, "state.name", "Illiteracy",
x<- c(4,7,11,16,20,22,25,26,33)
summary(x)
mode(x)
getmode(x)
getmode <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
x<- c(4,7,11,16,20,22,25,26,33)
summary(x)
getmode(x)
x<- c(4,7,11,16,20,22,22,25,26,33)
getmode(x)
plot(cars)
df
rm(list=ls())
source('~/.active-rstudio-document', echo=TRUE)
install.packages("drat", repos="https://cran.rstudio.com")
drat:::addRepo("dmlc")
install.packages("mxnet")
(39-30)/16
(39-30)/4
(40-30)/4
(21-30)/4
pnorm(40,mean = 30,sd=4)
pnorm(21,mean = 30,sd=4)
1- pnorm(21,mean = 30,sd=4)
pnorm(40,mean = 30,sd=4,1e-3)
pnorm(40,mean = 30,sd=4)
sprintf("%.3f",0.9937903)
foreach(STDIN)
sapply(STDIN,FUN = pnorm(STDIN,mean=30,sd=4))
STDIN <- c(40,21,30,35)
sapply(STDIN,FUN = pnorm(STDIN,mean=30,sd=4))
sapply(STDIN,FUN (pnorm(STDIN,mean=30,sd=4)))
sapply(STDIN,function(x) pnorm(STDIN,mean=30,sd=4))
pnorm(40,mean = 30,sd=4)
abc <-sapply(STDIN,function(x) pnorm(STDIN,mean=30,sd=4))
abc<-abc[,1]
abc
sprintf(%.3f,abc)
sapply(abc, function(x) sprintf(%.3f,abc))
sapply(abc, function(x) sprintf(%.3f,x))
sprintf(%.3f,x)
sprintf(%.3f,x[1,])
sprintf(%.3f,abc[1,])
abc[1,]
abc[1,]
abc
abc(1)
abc[1]
for(i<=length(abc))
length(abc)
Result[i]
result <- NULL
for(i<length(abc))
i=0
for(i<length(abc))
result <- sprintf("%.3f",abc[])
result
result <- sprintf("%.3f",abc)
result
abc[2] <- 1-abc[2]
abc[3] <- abc[3]-abc[4]
abc
abc[4]<- Null
abc[4]<- NA
abc
abc <- abc(1:3)
abc <- abc[1:3]
abc
result <- sprintf("%.3f",abc)
result
install.packages("drat", repos="https://cran.rstudio.com")
drat:::addRepo("dmlc")
install.packages("xgboost", repos="http://dmlc.ml/drat/", type = "source")
library(xgboost)
library('xgboost')
qnorm(0.05)
qnorm(0.95)
qno4m(0.99)
qnorm(0.99)
B = c(55,62,108,77,83,78,79,94,69,66,72,77)
A=  c(63,54,79,68,87,84,92,57,66,53,76,63)
t.test(A,B,alternative = "two.sided",paired = TRUE)
m = 5
stdDev = 2
n = 20
z = qnorm(1-0.025)
SE = z*stdDev/sqrt(n)
left_CI = m-SE
right_CI = m+SE
print(left_CI)
print(m)
print(right_CI)
O = c(956,10,9,9,7)
E = c(997,8,8,6,1)
chisq.test(O,E)
chisq.test(x=O,p=E)
E = c(.997,.008,.008,.006,.001)
chisq.test(x= O,p= E)
E = c(0.997,0.008,0.008,0.006,0.001)
chisq.test(x= O,p= E)
sum(E)
E = c(0.977,0.008,0.008,0.006,0.001)
sum(E)
chisq.test(x= O,p= E)
O = c(965,10,9,9,7)
E = c(0.977,0.008,0.008,0.006,0.001)
sum(E)
chisq.test(x= O,p= E)
Observed = c(965,10,9,9,7)
Expected = c(0.977,0.008,0.008,0.006,0.001)
sum(E)
chisq.test(x= Observed,p= Expected)
IntRate = c(7.43, 7.48, 8.00, 7.75, 7.60, 7.63
7.68, 7.67, 7.59, 8.07,8.03,8.00)
IntRate = c(7.43, 7.48, 8.00, 7.75, 7.60, 7.63,7.68, 7.67, 7.59, 8.07, 8.03, 8.00)
FutureIndex = c(221,222,226,225,224,223,226,226,235,233,241)
cov(IntRate,FutureIndex)
dim(FutureIndex)
length(FutureIndex)
length(IntRate)
FutureIndex = c(221,222,226,225,224,223,223,226,226,235,233,241)
cov(IntRate,FutureIndex)
cor(IntRate,FutureIndex)
E = c(44.688,5.88,47.432,43.32,5.7,45.98,25.992,3.42,27.58)
O = c(43,8,47,49,2,44,22,5,30)
length(O)
length(E)
chisq.test(x = O, p = E)
IntRate = c(7.43, 7.48, 8.00, 7.75, 7.60, 7.63,7.68, 7.67, 7.59, 8.07, 8.03, 8.00)
FutureIndex = c(221,222,226,225,224,223,223,226,226,235,233,241)
cov(IntRate,FutureIndex)
cor(IntRate,FutureIndex)
Observed = c(965,10,9,9,7)
Expected = c(0.977,0.008,0.008,0.006,0.001)
chisq.test(x= Observed,p= Expected)
setwd("C:/Users/quadris/Desktop/My Learning/INSOFE CPEE/Day 8 Linear Regression/20171401_Batch24_CSE7202c_LinearRegression_Lec01/Supporting Excel,R files")
carstop <- read.csv("SpeedVsStopNADA.csv", header = T, sep = ",")
lmstop <- lm(StopDist.ft~ Speed.mph, data=carstop )
summary(lmstop)
carstop
summary(lmstop)
shapiro.test(lmstop$residuals)  # Check if the residuals are Normally distributed
library(ggplot2)
ggplot(carstop,aes(x=Speed.mph, y=StopDist.ft)) + geom_point()+geom_smooth(method="loess")
with(carstop, scatter.smooth(Speed.mph,StopDist.ft,family="gaussian"))
plot(lmstop$residuals)
setwd("C:/Users/quadris/Desktop/My Learning/INSOFE CPEE/Day 8 Linear Regression/20171401_Batch24_CSE7202c_LinearRegression_Lec01/Supporting Excel,R files")
wordRecall <- read.csv("wordRecall.csv")
plot(wordRecall)
plot(log(wordRecall$time),wordRecall$prop)
wordRecall
lmRecall <- lm(prop~log(time),wordRecall)
summary(lmRecall)
require(plot3D)
attach(mtcars)
fit <- lm(mpg ~ wt+hp)
wt.pred <- seq(1.5, 5.5, length.out = 30)
hp.pred <- seq(65, 230, length.out = 30)
xy <- expand.grid(wt = wt.pred,
hp = hp.pred)
mpg.pred <- matrix (nrow = 30, ncol = 30,
data = predict(fit, newdata = data.frame(xy), interval = "prediction"))
fitpoints <- predict(fit)
scatter3D(z = mpg, x = wt, y = hp, pch = 18, cex = 2,
theta = 20, phi = 20, ticktype = "detailed",
xlab = "wt", ylab = "hp", zlab = "mpg", clab = "mpg",
surf = list(x = wt.pred, y = hp.pred, z = mpg.pred,
facets = NA, fit = fitpoints),
colkey = list(length = 0.8, width = 0.4),
main = "mtcars")
detach(mtcars)
require(plot3D)
install.packages("plot3D")
require(plot3D)
attach(mtcars)
fit <- lm(mpg ~ wt+hp)
wt.pred <- seq(1.5, 5.5, length.out = 30)
hp.pred <- seq(65, 230, length.out = 30)
xy <- expand.grid(wt = wt.pred,
hp = hp.pred)
mpg.pred <- matrix (nrow = 30, ncol = 30,
data = predict(fit, newdata = data.frame(xy), interval = "prediction"))
fitpoints <- predict(fit)
scatter3D(z = mpg, x = wt, y = hp, pch = 18, cex = 2,
theta = 20, phi = 20, ticktype = "detailed",
xlab = "wt", ylab = "hp", zlab = "mpg", clab = "mpg",
surf = list(x = wt.pred, y = hp.pred, z = mpg.pred,
facets = NA, fit = fitpoints),
colkey = list(length = 0.8, width = 0.4),
main = "mtcars")
summary(fit)
fitpoints
mtcars
fit <- lm(mpg ~ mtcars)
wordRecall
